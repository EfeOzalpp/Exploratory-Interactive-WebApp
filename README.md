# ğŸŒ Participatory Climate App â€” 3D Interactive Survey Experience

<div style="display: flex; justify-content: center; gap: 1rem; flex-wrap: wrap;">
  <div>
    <img src="./project_screenshots/6.png" style="width: 45%; min-width: 300px;" alt="Climate Inclusive App">
    <img src="./project_screenshots/8.png" style="width: 45%; min-width: 300px;" alt="Climate Inclusive App">
  </div>
  <div>
    <img src="./project_screenshots/2.png" style="width: 45%; min-width: 300px;" alt="Climate Inclusive App">
    <img src="./project_screenshots/1.png" style="width: 45%; min-width: 300px;" alt="Climate Inclusive App">
  </div>
</div>


**Participatory Climate App** is a fully interactive web application that visualizes survey results about climate change in a **gamified 3D environment**.  

After completing a short climate survey, users receive **personalized feedback** represented through color-coded, world-anchored cards â€” and can explore **other participantsâ€™ results** in a live, orbitable 3D world.

---

## ğŸ® Features

- ğŸ§© **Gamified Feedback Cards**  
  Personalized results based on each answer â€” with adaptive gradients, contextual tone, and subtle motion.

- ğŸŒ **3D Visualization with Three.js & React Three Fiber**  
  Explore other survey takersâ€™ results floating in space â€” orbit, zoom, and interact with dynamic nodes powered by custom layout logic.

- ğŸ–¼ï¸ **Custom 2D Canvas Engine**  
  A lightweight, hand-built engine (not dependent on p5.js or PixiJS) for rendering animated environmental shapes like clouds, houses, buses, and trees.

- ğŸ§­ **Responsive & Touch-Ready UI**  
  Pinch-zoom, drag, rotate, and toggle elements fluidly â€” optimized for accessibility and motion-comfort.

- âš™ï¸ **Dynamic Offset Anchoring System**  
  Keeps 2D DOM elements visually attached to their 3D anchors, even during camera motion.  
  Handles viewport edge cases automatically using `.is-top`, `.is-bottom`, etc. classes.

---

## ğŸ§  Technical Highlights

```markdown
### ğŸ¯ Bridging 3D Context with React DOM

The app integrates **Three.js (via React Three Fiber)** and **React DOM** through a custom anchoring system.  
Normally, `@react-three/drei`â€™s `Html` component struggles to keep labels aligned during camera motion.  
This project introduces a **dynamic offset value system** to preserve spatial alignment and visual consistency.

    transform: translateX(var(--offset-px));

This allows each element to stay visually locked to its projected 3D anchor â€” even while orbiting or zooming â€” preventing UI â€œfloatâ€ drift that usually breaks immersion.

ğŸ™ï¸ **Procedural City Generation Engine**

A procedural City Engine governs every structure, vehicle, and environmental shape based on the userâ€™s `liveAvg`.  
It uses a **Condition Planner System (Aâ€“D)** with quota curves, shape footprints, and per-band rules that automatically rebalance across viewports (start, questionnaire, overlay).

ğŸ§© **Adaptive Grid & Placement Logic**

A logical grid abstracts the viewport into responsive â€œcellsâ€:

- Dynamic row/column count derived from screen dimensions  
- Per-shape forbidden zones for spatial clarity  
- Deterministic pseudo-randomness for organic variation  

This enables a natural yet reproducible layout of city elements â€” purely procedural, no physics required.  
In **overlay mode**, the centering bias is disabled to let `RowRules` fully dictate placement, resulting in a more cinematic spread.

ğŸ¨ **Dual Rendering Pipelines (DOM + Canvas)**

The app blends **React DOM** for interactivity and a **Q5-based Canvas Engine** for the visual world.  
Both share global state through `GraphContext`, allowing smooth continuity between the questionnaire, overlay, and results â€” keeping the city simulation persistent across phases.

âš™ï¸ **Deterministic World Planning**

Every elementâ€™s position is reproducible, generated via hashed IDs:

    const key = `${shape}|${row},${col}`;
    const rand = hash32(key) / 0xffff;

This guarantees consistent yet natural variety between sessions.

ğŸŒ¤ï¸ **Gradient & Environmental Reactivity**

In overlay mode, a bottom-to-top gradient dynamically shifts hue based on the userâ€™s `liveAvg`.  
The base color intensifies according to survey sentiment â€” cool blues for low averages, warm ambers for high â€” while fading to transparent near the top, blending data and emotion into atmosphere.

ğŸ§± **Engine Architecture for Extensibility**

The system operates as a mini engine, not a static animation.  
Adding a new environment type or shape is as simple as defining its footprint and quota â€” the engine automatically handles placement, scaling, and spatial logic.

    { shape: 'tower', footprint: { w: 1, h: 4 } }

Everything else â€” positioning, balancing, and color blending â€” is procedurally resolved.

ğŸ§© **Stack**

- React + TypeScript  
- React Three Fiber / Drei  
- Custom Q5 Engine (procedural 2D rendering)  
- Framer Motion  
- Context API  
- CSS Grid / Tailwind principles  

ğŸš€ **Local Setup**

    git clone https://github.com/yourusername/participatory-climate-app
    cd participatory-climate-app
    npm install
    npm run dev

Then open [http://localhost:3000](http://localhost:3000) in your browser.

âœ¨ **Vision**

The project bridges data, storytelling, and interactivity â€” turning climate perception into a tangible, explorable world.  
Itâ€™s not just a survey â€” itâ€™s a participatory landscape that visualizes how we feel about the planet.

ğŸ§­ **Development Philosophy**

This app was designed as both a tool and a canvas â€” an engine that merges data visualization with emotion.  
Every architectural decision aims to keep the system reactive, procedural, and human:

- Reactive systems > scripted animations  
  The world doesnâ€™t play back â€” it *responds* to live data.

- Minimal dependencies, maximal flexibility  
  The canvas engine is written from scratch for precise control over rendering and motion.

- Extensible at the rule level  
  Adding a new condition or city element requires no structural rewrite â€” only new rule definitions.

The result is a living interface â€” part visualization, part expression, and entirely driven by human input.

> â€œInstead of showing charts about climate â€” we built a world that feels it.â€
```
